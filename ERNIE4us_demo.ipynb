{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate loading and using ERNIE4us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo loading the ERNIE2 model and preparing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataclasses\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from ernie4us import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ernie_input_builder, ernie_tf_inputs, ernie_tf_outputs = load_ernie_model(ERNIE_BASE_EN,\n",
    "    \"./model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.compat.v1.Session(graph=ernie_tf_inputs.token_ids.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializers = [i for i in [tf.compat.v1.global_variables_initializer(),\n",
    "                            tf.compat.v1.local_variables_initializer()] if i]\n",
    "session.run(initializers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, op in enumerate(session.graph.get_operations()):\n",
    "    if op.type == 'Const':\n",
    "        tensor = session.graph.get_tensor_by_name(op.name + ':0')\n",
    "        print(i, '\\t', tensor, tensor.op.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo ERNIE tensorflow usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_a = \"ERNIE for the rest of us\"\n",
    "text_b = \"thank you ERNIE\"\n",
    "\n",
    "record = ernie_input_builder.build(text_a, text_b,task_id=0)\n",
    "for key, item in dataclasses.asdict(record).items():\n",
    "    print(f'{key}', item.shape, '=>', np.reshape(item, (512,))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(session, record, fetches):\n",
    "    return session.run(\n",
    "        fetches, \n",
    "        feed_dict={\n",
    "            ernie_tf_inputs.token_ids: record.token_ids,\n",
    "            ernie_tf_inputs.sentence_ids: record.sentence_ids,\n",
    "            ernie_tf_inputs.position_ids: record.position_ids,\n",
    "            ernie_tf_inputs.task_ids: record.task_ids,\n",
    "            ernie_tf_inputs.input_mask: record.input_mask})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: dataclasses.astuple() caused errors on field values of type tf.Tensor\n",
    "fetches = [ernie_tf_outputs.sequence_features, ernie_tf_outputs.classification_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with session.as_default():\n",
    "    print(session.graph.get_tensor_by_name('src_ids:0'))\n",
    "    initializers = [i for i in [tf.compat.v1.global_variables_initializer(),\n",
    "                                tf.compat.v1.local_variables_initializer()] if i]\n",
    "    session.run(initializers)\n",
    "    print('n. local vars:', len(tf.local_variables()), 'n. global vars:', len(tf.global_variables()))\n",
    "    ernie_sequence_features, ernie_classification_features = run_model(session, record, fetches)\n",
    "    print(ernie_classification_features.shape, ernie_sequence_features.shape)\n",
    "    st = time.time()\n",
    "    n_times = 20\n",
    "    for _ in range(n_times):\n",
    "        run_model(session, record, fetches)\n",
    "    dt = time.time() - st\n",
    "    print(f\"finished in {dt}s. avg {dt / n_times}s/request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with session.as_default():\n",
    "    num_class = 3\n",
    "    with tf.variable_scope(\"classifier\", reuse=tf.AUTO_REUSE):\n",
    "        output_weights = tf.get_variable(\n",
    "            \"logits_W\", [num_class, ernie_tf_outputs.classification_features.shape[-1]],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        output_bias = tf.get_variable(\n",
    "            \"logits_b\", [num_class], initializer=tf.zeros_initializer())\n",
    "        ernie_classification_features = tf.nn.dropout(ernie_tf_outputs.classification_features, \n",
    "                                                    rate=get_dropout_rate_tensor(0.2))\n",
    "        logits = tf.matmul(ernie_classification_features, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        logits = tf.nn.leaky_relu(logits)\n",
    "        print('classifier logits.shape', logits.shape)\n",
    "    initializers = [i for i in [tf.compat.v1.global_variables_initializer(),\n",
    "                                tf.compat.v1.local_variables_initializer()] if i]\n",
    "    session.run(initializers)\n",
    "    print('n. local vars:', len(tf.local_variables()), 'n. global vars:', len(tf.global_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session.as_default():\n",
    "    batch_size = 3\n",
    "    token_ids2 = np.squeeze(np.stack([record.token_ids] * batch_size, axis=0), axis=1)\n",
    "    sentence_ids2 = np.squeeze(np.stack([record.sentence_ids] * batch_size, axis=0), axis=1)\n",
    "    position_ids2 = np.squeeze(np.stack([record.position_ids] * batch_size, axis=0), axis=1)\n",
    "    task_ids2 = np.squeeze(np.stack([record.task_ids] * batch_size, axis=0), axis=1)\n",
    "    input_mask2 = np.squeeze(np.stack([record.input_mask] * batch_size, axis=0), axis=1)\n",
    "    record2 = Ernie2Input(token_ids2, sentence_ids2, position_ids2, task_ids2, input_mask2)\n",
    "    logits_out = run_model(session, record2, [logits])\n",
    "    print(logits_out[0].shape)\n",
    "    st = time.time()\n",
    "    n_times = 20\n",
    "    for _ in range(n_times):\n",
    "        run_model(session, record2, [logits])\n",
    "    dt = time.time() - st\n",
    "    print(f\"finished in {dt}s. avg {dt / n_times}s/req avg {dt / n_times / batch_size}s/item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "before_squeezed = np.stack([record.token_ids] * batch_size, axis=0)\n",
    "token_ids2 = np.squeeze(before_squeezed, axis=1)\n",
    "before_squeezed.shape, token_ids2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
