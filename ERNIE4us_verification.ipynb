{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying paddle to tensorflow model conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from ernie4us import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ernie_model = ERNIE_LARGE_EN\n",
    "ernie_path = 'model_artifacts/%s' % ernie_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    ernie_input_builder, ernie_layer = load_ernie_model(ernie_model, \"./model_artifacts\")\n",
    "    tf_inputs = ernie_input_builder.build(\"hellow world\")\n",
    "    _ = ernie_layer(tf_inputs.as_tuple())\n",
    "    for i, op in enumerate(g.get_operations()):\n",
    "        if op.type == 'Const':\n",
    "            tensor = g.get_tensor_by_name(op.name + ':0')\n",
    "            print(i, '\\t', tensor, tensor.op.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ernie_input_builder, ernie_layer = load_ernie_model(ernie_model, \"./model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# NOTE(paddle-dev): All of these flags should be\n",
    "# set before `import paddle`. Otherwise, it would\n",
    "# not take any effect.\n",
    "os.environ['FLAGS_eager_delete_tensor_gb'] = '0'  # enable gc\n",
    "\n",
    "import paddle.fluid as fluid\n",
    "\n",
    "try:\n",
    "    from model.ernie import ErnieConfig\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.insert(0, os.path.join('third_party', 'ERNIE'))\n",
    "\n",
    "from model.ernie import ErnieConfig\n",
    "from utils.init import init_pretraining_params, init_checkpoint\n",
    "from model.ernie import ErnieModel\n",
    "\n",
    "max_seq_len=512\n",
    "\n",
    "def create_model(ernie_config):\n",
    "    input_names = (\"src_ids\", \"sent_ids\", \"pos_ids\", \"task_ids\", \"input_mask\")\n",
    "    shapes=[[-1, max_seq_len, 1], [-1, max_seq_len, 1],\n",
    "            [-1, max_seq_len, 1], [-1, max_seq_len, 1],\n",
    "            [-1, max_seq_len, 1]]\n",
    "    dtypes=[\n",
    "        'int64', 'int64', 'int64', 'int64', 'float32'\n",
    "    ]\n",
    "\n",
    "    inputs = [fluid.data(name, shape, dtype=dtype) for name, shape, dtype in zip(input_names, shapes, dtypes)]\n",
    "    (src_ids, sent_ids, pos_ids, task_ids, input_mask) = inputs\n",
    "\n",
    "    ernie = ErnieModel(\n",
    "        src_ids=src_ids,\n",
    "        position_ids=pos_ids,\n",
    "        sentence_ids=sent_ids,\n",
    "        task_ids=task_ids,\n",
    "        input_mask=input_mask,\n",
    "        config=ernie_config,\n",
    "        use_fp16=False)\n",
    "\n",
    "    seq_out = ernie.get_sequence_output()\n",
    "    cls_feats = ernie.get_pooled_output()\n",
    "    # dummy layers to name the latent layers. the save_inf_model produce uncomprehensible names\n",
    "    # like 'save_infer_model/scale_1'\n",
    "    seq_out = fluid.layers.scale(seq_out, scale=1.0, name='ernie_sequence_latent')\n",
    "    cls_feats = fluid.layers.scale(cls_feats, scale=1.0, name='ernie_classification')\n",
    "\n",
    "    for i, inp in enumerate(inputs):\n",
    "        print(f'input[{i}]:', inp.name, inp.shape, inp.dtype)\n",
    "    print('sequence_output  :', seq_out.name, seq_out.shape, seq_out.dtype)\n",
    "    print('classifier_output:', cls_feats.name, cls_feats.shape, cls_feats.dtype)\n",
    "    return inputs, [seq_out, cls_feats]\n",
    "\n",
    "\n",
    "pretraining_params_path = f'{ernie_path}/paddle/params'\n",
    "ernie_config_path = f'{ernie_path}/paddle/ernie_config.json'\n",
    "ernie_vocab_path = f'{ernie_path}/paddle/vocab.txt'\n",
    "ernie_config = ErnieConfig(ernie_config_path)\n",
    "# Fix missing use_task_id\n",
    "ernie_config._config_dict['use_task_id'] = True\n",
    "ernie_config.print_config()\n",
    "\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "\n",
    "startup_prog = fluid.Program()\n",
    "predict_prog = fluid.Program()\n",
    "\n",
    "with fluid.program_guard(predict_prog, startup_prog):\n",
    "    with fluid.unique_name.guard():\n",
    "        inputs, ernie_latent = create_model(ernie_config=ernie_config)\n",
    "        predict_prog = predict_prog.clone(for_test=True)\n",
    "with fluid.program_guard(predict_prog, startup_prog):\n",
    "    init_pretraining_params(\n",
    "        exe,\n",
    "        pretraining_params_path,\n",
    "        main_program=startup_prog,\n",
    "        use_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "output_paddle_names = []\n",
    "with fluid.program_guard(predict_prog, startup_prog):\n",
    "    block = predict_prog.global_block()\n",
    "    for op in block.ops:\n",
    "        print(op.type, op.output(op.output_names[0]), len(op.output_names))\n",
    "        for on in op.output_names:\n",
    "            output_paddle_names.extend(op.output(on))\n",
    "output_tf_names = [n.replace('@', '_') for n in output_paddle_names]\n",
    "print(len(output_paddle_names), len(output_tf_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "type(ernie_latent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def zip_tf_feed_dict(tensors, values):\n",
    "    feed_dict = {getattr(tensors, field.name): values[field.name] if isinstance(values, dict) \n",
    "                 else getattr(values, field.name) for field in dataclasses.fields(tensors)}\n",
    "    for tensor in feed_dict.keys():\n",
    "        assert isinstance(tensor, tf.Tensor), f\"key is of type {tensor}\"\n",
    "    return feed_dict\n",
    "\n",
    "with fluid.program_guard(predict_prog, startup_prog):\n",
    "    text = \"Apartment was okay still some fixtures to be done in bathroom. Hallways walls need to be cleaned and painted. narrow hallways. and hallway rugs need to be cleaned.\"\n",
    "\n",
    "    paddle_input_builder = Ernie2InputBuilder(ernie_vocab_path, do_lower_case=True, max_seq_len=max_seq_len)\n",
    "    paddle_inputs = paddle_input_builder.build(text)\n",
    "    n_tokens = list(paddle_inputs.token_ids[0]).index(paddle_input_builder.pad_id)\n",
    "    print(f\"n tokens {n_tokens}\")\n",
    "    position_ids = paddle_input_builder.pad_input_seq(list(range(n_tokens)), paddle_input_builder.pad_id, dtype=np.int64)\n",
    "    paddle_inputs = {\n",
    "        \"src_ids\": np.reshape(paddle_inputs.token_ids, (1, -1, 1)),\n",
    "        \"sent_ids\": np.reshape(paddle_inputs.sentence_ids, (1, -1, 1)), \n",
    "        \"pos_ids\": np.reshape(position_ids, (1, -1, 1)), \n",
    "        \"task_ids\": np.reshape(paddle_inputs.task_ids, (1, -1, 1)),\n",
    "        \"input_mask\": np.reshape(paddle_inputs.input_mask, (1, -1, 1))\n",
    "    }\n",
    "    paddle_latent = exe.run(fluid.default_main_program(),\n",
    "          feed=paddle_inputs,\n",
    "          fetch_list=ernie_latent[1])[0]\n",
    "    tf_inputs = ernie_input_builder.build(text)\n",
    "    _, tf_latent = ernie_layer(tf_inputs.as_tuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cos_dist = np.dot(paddle_latent, np.transpose(tf_latent)) \\\n",
    "    / (np.linalg.norm(paddle_latent) * np.linalg.norm(tf_latent))\n",
    "cos_dist = np.reshape(cos_dist, [])\n",
    "print('paddle_latent>', paddle_latent.shape, 'tf_latent>', tf_latent.shape,\n",
    "      float(cos_dist))\n",
    "assert cos_dist > 0.9999"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}